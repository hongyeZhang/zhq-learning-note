


## 优点
* 解耦
* 异步
* 削峰

## 缺点
* 系统复杂性升高，需要保证高可用
    - 你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？
* 系统的可用性降低，出现各种故障及bug
* 分布式条件下的一致性问题



## 消息中间件选型

RabbitMQ，他的好处在于可以支撑高并发、高吞吐、性能很高，同时有非常完善便捷的后台管理界面可以使用。
另外，他还支持集群化、高可用部署架构、消息高可靠支持，功能较为完善。
RabbitMQ的开源社区很活跃，较高频率的迭代版本，来修复发现的bug以及进行各种优化，因此综合考虑过后，公司采取了RabbitMQ。


RocketMQ，是阿里开源的，经过阿里的生产环境的超高并发、高吞吐的考验，性能卓越，同时还支持分布式事务等特殊场景。

另外就是Kafka。Kafka提供的消息中间件的功能明显较少一些，相对上述几款MQ中间件要少很多。
但是Kafka的优势在于专为超高吞吐量的实时日志采集、实时数据同步、实时数据计算等场景来设计。









## RabbitMQ
* RabbitMQ 丢失数据的情况？
    - 生产者端。消息因为网络问题丢失或者发送到RabbitMQ的时候出错
    - rabbitMQ服务器未做持久化
    - 消费者端。打开了autoAck。未完成消费之前就自动回复了。

* RabbitMQ 丢失数据怎样解决？
    - 生产者端：通过confirm模式异步确认消息是否发送成功。在失败的回调函数中处理发送失败的逻辑
    - rabbitMQ端： 打开持久化机制。
        - 建立 queue 的时候，持久化queue
        - 生产者发消息的时候，deliverMode=2，让MQ将消息也持久化
        - 极端情况下，内存的数据未来得及持久化，也会丢失
    - 消费者端： 去掉自动AutoACK，消费逻辑处理结束之后手动提交ACK。

## Kafka
* Kafka 丢失数据的情况？
    - 生产者端：如果确认写成功，也没有重发会丢失。
    - 服务端：如果没有来的及和节点同步就宕机，则这部分数据丢失
    - 消费者端：如果自动提交offset会造成数据丢失

* Kafka 丢失数据怎样解决？
    - 生产者端：设置参数，每个从节点都写成功后才任务成功，如果发送失败，重试次数要设置一个很大的值
    - 服务端：设置参数，要求从节点起码大于1，至少有一个能够被感知到
    - 消费者端：取消自动回复。强一致的保证消息不丢失，会影响到吞吐量
    
    

## 高可用

### RabbitMQ 高可用
* 基于主从（非分布式）做高可用性
    - 单机模式
    - 普通集群模式
        - 没有什么所谓的高可用性，这方案主要是提高吞吐量的
    - 镜像集群模式 （高可用性）
        - 不能横向扩容，做不到线性扩展
* 本质并不是一个分布式的消息队列，设计理念就不是。


### RabbitMQ 解决消息丢失问题
* 生产者 -> RabbitMQ
    - 发送时开启事务机制（同步）
    - 开启 confirm 机制 （异步）
* RabbitMQ 本身
    - 队列、消息持久化处理
    - 高可用部署
* 消费者
    - 手动 ACK




## 重复消费问题
* 具体的解决思路（与业务有关系）
    - 比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update 一下好吧。
    - 比如你是写 Redis，那没问题了，反正每次都是 set，天然幂等性。
    - 比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的 id，类似订单 id 之类的东西，然后你这里消费到了之后，先根据这个 id
     去比如 Redis 里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个 id 写 Redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。
    - 比如基于数据库的唯一键来保证重复数据不会重复插入多条。因为有唯一键约束了，重复数据插入只会报错，不会导致数据库中出现脏数据






