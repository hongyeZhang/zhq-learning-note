


## 基础数据结构
string
    - 当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。
list
    - Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)，这点让人非常意外。
      当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。
      Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理
hash 
    - hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。
    这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。
set 
zset
    - zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，
    一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。
    它的内部实现用的是一种叫着「跳跃列表」的数据结构
    - zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。
    - 跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。
    然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。
    - 定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问，那新插入的元素如何才有机会「身兼数职」呢？
      跳跃列表采取一个随机策略来决定新元素可以兼职到第几层。
    - zset 可以用来实现高性能的延时队列， 存储时间戳，不断进行轮询，如果符合要求 就拿出来。
    - 为什么不选用AVL树或者红黑树？
        - 因为AVL树在极端情况下会退化成链表，O(N)的时间复杂度
        - 红黑树的操作太麻烦了


## 缓存相关
* 缓存穿透
* 缓存击穿
* 缓存雪崩


* 如何保证缓存与数据库的双写一致性？



## 分布式寻址算法
* hash 算法（大量缓存重建）
* 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
* redis cluster 的 hash slot 算法


## 一致性hash
一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）









## 应用场景
* 延时队列： 没有ACK机制，不推荐使用
* 位图
    - 主要是节省空间
    - 统计用户的签到，将 bool 类型数据的统计转化为 位 的统计
    - Redis 的位数组是自动扩展，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩
    - 统计和查找
        - Redis 提供了位图统计指令 bitcount 和位图查找指令 bitpos，bitcount 用来统计指定位置范围内 1 的个数，
          bitpos 用来查找指定范围内出现的第一个 0 或 1。


## 高级数据结构以及应用

* HyperLogLog
    - HyperLogLog 提供不精确的去重计数方案，虽然不精确但是也不是非常不精确，标准误差是 0.81%
    - HyperLogLog 提供了两个指令 pfadd 和 pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数
    - HyperLogLog 这个数据结构不是免费的，不是说使用这个数据结构要花钱，它需要占据一定 12k 的存储空间，所以它不适合统计单个用户相关的数据。
        如果你的用户上亿，可以算算，这个空间成本是非常惊人的。但是相比 set 存储方案，HyperLogLog 所使用的空间那真是可以使用千斤对比四两来形容了。
    - pfmerge 将两个统计结果合并
    - 应用场景
        - 统计一个网页的UV（独立访客数目）
        - 只要是去重的统计都行，避免 set，前提是可以容忍不精确
        - 只提供计数，不提供是否存在的校验

* 布隆过滤器
    - 布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。
      但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。
      当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。
    - bf.add 添加元素，bf.exists 查询元素是否存在
    - 如果误判率过高，则需要调参。key, error_rate和initial_size  错误率越低，需要的空间越大
    - Redis4.0 之后提供的
    
    - 应用场景
        - 新闻客户端推荐系统如何实现推送去重的？
        - 爬虫系统  URL 去重
         -垃圾邮件过滤（也可以用贝叶斯分类）

* 简单限流
    - Zset 滑动窗口实现

* 漏斗限流
    - Redis 4.0 提供了一个限流 Redis 模块，它叫 redis-cell。
    - 实现分布式限流
* GeoHash
    - Redis 在 3.2 版本以后增加了地理位置 GEO 模块，意味着我们可以使用 Redis 来实现摩拜单车「附近的 Mobike」、美团和饿了么「附近的餐馆」这样的功能
    - 在使用 Redis 进行 Geo 查询时，我们要时刻想到它的内部结构实际上只是一个 zset(skiplist)。
      通过 zset 的 score 排序就可以得到坐标附近的其它元素 (实际情况要复杂一些，不过这样理解足够了)，通过将 score 还原成坐标值就可以得到元素的原始坐标。
    - georadiusbymember 指令是最为关键的指令，它可以用来查询指定元素附近的其它元素，它的参数非常复杂
    - 范围 20 公里以内最多 3 个元素按距离正排，它不会排除自身
        - 127.0.0.1:6379> georadiusbymember company ireader 20 km count 3 asc
    - Redis 还提供了根据坐标值来查询附近的元素，这个指令更加有用，它可以根据用户的定位来计算「附近的车」，「附近的餐馆」等
    - 在一个地图应用中，车的数据、餐馆的数据、人的数据可能会有百万千万条，如果使用 Redis 的 Geo 数据结构，它们将全部放在一个 zset 集合中。
      在 Redis 的集群环境中，集合可能会从一个节点迁移到另一个节点，如果单个 key 的数据过大，会对集群的迁移工作造成较大的影响，在集群环境中单个 
      key 对应的数据量不宜超过 1M
      ，否则会导致集群迁移出现卡顿现象，影响线上服务的正常运行。
      所以，这里建议 Geo 的数据使用单独的 Redis 实例部署，不使用集群环境。
      如果数据量过亿甚至更大，就需要对 Geo 数据进行拆分，按国家拆分、按省拆分，按市拆分，在人口特大城市甚至可以按区拆分。这样就可以显著降低单个
       zset 集合的大小












## 分布式锁
* 加锁： setnx  expire  value为一个随机值
* 解锁： 通过 lua 脚本实现，需要判断改锁是不当前线程加的
* 过期续命问题
* 可重入问题（线程内部包装一个 threadLocal对象），同样需要考虑超时问题，不建议使用





## 基本原理
### 线程 IO 模型
* Redis 是个单线程程序！这点必须铭记。
也许你会怀疑高并发的 Redis 中间件怎么可能是单线程。很抱歉，它就是单线程，你的怀疑暴露了你基础知识的不足。莫要瞧不起单线程，除了 Redis 之外，Node.js 也是单线程，Nginx 也是单线程，但是它们都是服务器高性能的典范。

* Redis 单线程为什么还能这么快？
因为它所有的数据都在内存中，所有的运算都是内存级别的运算。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些时间复杂度为 O(n) 级别的指令，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。

* 事件轮询 (多路复用)

### 通信协议
* RESP(Redis Serialization Protocol)

### 持久化
* RDB 快照
    - 快照是内存数据的二进制序列化形式，在存储上非常紧凑
    - Redis 使用操作系统的多进程 COW(Copy On Write) 机制来实现快照持久
    - Redis 在持久化时会调用 glibc 的函数fork产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。
      子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。
* AOF 日志
    - 日志记录的是内存数据修改的指令记录文本
    - AOF 日志在长期的运行过程中会变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。
       所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。
    - AOF 日志存储的是 Redis 服务器的顺序指令序列，AOF 日志只记录对内存进行修改的指令记录
    - Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。其原理就是开辟一个子进程对内存进行遍历转换成一系列 
      Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 
      AOF 日志文件中，追加完毕后就立即替代旧的 AOF日志文件了，瘦身工作就完成了。

快照是通过开启子进程的方式进行的，它是一个比较耗资源的操作。
1、遍历整个内存，大块写磁盘会加重系统负载
2、AOF 的 fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系统 IO 负担

所以通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛


### 管道
它并不是服务器的什么特性，而是客户端通过改变了读写的顺序带来的性能的巨大提升。


### 事务
multi/exec/discard。multi 指示事务的开始，exec 指示事务的执行，discard 指示事务的丢弃。

所有的指令在 exec 之前不执行，而是缓存在服务器的一个事务队列中，服务器一旦收到 exec 指令，才开执行整个事务队列，
执行完毕后一次性返回所有指令的运行结果。因为 Redis 的单线程特性，它不用担心自己在执行队列的时候被其它指令打搅，可以保证他们能得到的「原子性」执行。

* 你应该明白 Redis 的事务根本不能算「原子性」，而仅仅是满足了事务的「隔离性」，隔离性中的串行化——当前执行的事务有着不被其它事务打断的权利
    - 仅仅是保证了串行化
* Redis 为事务提供了一个 discard 指令，用于丢弃事务缓存队列中的所有指令，在 exec 执行之前。
* Redis 事务在发送每个指令到事务缓存队列时都要经过一次网络读写，当一个事务内部的指令较多时，需要的网络 IO 时间也会线性增长。
  所以通常 Redis 的客户端在执行事务时都会结合 pipeline 一起使用，这样可以将多次 IO 操作压缩为单次 IO 操作
* 提供了这种 watch 的机制，它就是一种乐观锁。 分布式锁是一种悲观锁。
* watch 会在事务开始之前盯住 1 个或多个关键变量，当事务执行时，也就是服务器收到了 exec 指令要顺序执行缓存的事务队列时，
  Redis 会检查关键变量自 watch 之后，是否被修改了 (包括当前事务所在的客户端)。如果关键变量被人动过了，exec 指令就会返回 null
  回复告知客户端事务执行失败，这个时候客户端一般会选择重
  - 是通过在 exec 方法里返回一个 null，这样客户端需要检查一下返回结果是否为 null 来确定事务是否执行失败



### 内存回收
* Redis 并不总是可以将空闲内存立即归还给操作系统。
  如果当前 Redis 内存有 10G，当你删除了 1GB 的 key 后，再去观察内存，你会发现内存变化不会太大。原因是操作系统回收
  内存是以页为单位，如果这个页上只要有一个 key 还在使用，那么它就不能被回收。Redis 虽然删除了 1GB 的 key，但是这些
   key 分散到了很多页面中，每个页面都还有其它 key 存在，这就导致了内存不会立即被回收。


### 主从同步
* CAP 原理就是——网络分区发生时，一致性和可用性两难全
 C - Consistent ，一致性
 A - Availability ，可用性
 P - Partition tolerance ，分区容忍性

* Redis 同步支持主从同步和从从同步，从从同步功能是 Redis 后续版本增加的功能，为了减轻主库的同步负担。后面为了描述上的方便，统一理解为主从同步。

* 直接看书上的介绍
* 增量同步
* 快照同步

* Redis 的复制是异步进行的，wait 指令可以让异步复制变身同步复制，确保系统的强一致性 (不严格)
* wait 提供两个参数，第一个参数是从库的数量 N，第二个参数是时间 t，以毫秒为单位。它表示等待 wait 指令之前的所有写
操作同步到 N 个从库 (也就是确保 N 个从库的同步没有滞后)，最多等待时间 t。
* 主从复制是 Redis 分布式的基础，Redis 的高可用离开了主从复制将无从进行。后面的章节我们会开始讲解 Redis 的集群模式，
这几种集群模式都依赖于本节所讲的主从复制。


* 如果redis只做缓存，则不需要主从复制
* 如果是需要持久化功能，则需要仔细对待主从复制问题


### Sentinel
它负责持续监控主从节点的健康，当主节点挂掉时，自动选择一个最优的从节点切换为主节点。客户端来连接集群时，会首先连接 sentinel，
通过 sentinel 来查询主节点的地址，然后再去连接主节点进行数据交互。当主节点发生故障时，客户端会重新向 sentinel 要地址，sentinel 会将最新的主节点地址告诉客户端

Redis 主从采用异步复制，意味着当主节点挂掉时，从节点可能没有收到全部的同步消息，这部分未同步的消息就丢失了。如果主从延迟特别大，那么丢失的数据就可能会特别多。Sentinel 无法保证消息完全不丢失，但是也尽可能保证消息少丢失。它有两个选项可以限制主从延迟过大。
min-slaves-to-write 1
min-slaves-max-lag 10
第一个参数表示主节点必须至少有一个从节点在进行正常复制，否则就停止对外写服务，丧失可用性。
何为正常复制，何为异常复制？这个就是由第二个参数控制的，它的单位是秒，表示如果 10s 没有收到从节点的反馈，就意味着从节点同步不正常，要么网络断开了，要么一直没有给反馈。


* 监控
* 选主


### Codis
* 充当代理的功能，维护1024个槽位，不同的槽位对应不同的redis实例
* 结合 zookeeper, codis 也可以做集群处理，做到高可用。
* Codis 给 Redis 带来了扩容的同时，也损失了其它一些特性。因为 Codis 中所有的 key 分散在不同的 Redis 实例中，
  所以事务就不能再支持了，事务只能在单个 Redis 实例中完成。

* Codis 的优点
Codis 在设计上相比 Redis Cluster 官方集群方案要简单很多，因为它将分布式的问题交给了第三方 zk/etcd 去负责，
自己就省去了复杂的分布式一致性代码的编写维护工作。而 Redis Cluster 的内部实现非常复杂，它为了实现去中心化，
混合使用了复杂的 Raft 和 Gossip 协议，还有大量的需要调优的配置参数，当集群出现故障时，维护人员往往不知道从何处着手

* BUT  不是官方的项目，更新比较滞后，地位比较尴尬


### Cluster
* RedisCluster 是 Redis 的亲儿子，它是 Redis 作者自己提供的 Redis 集群化方案
* 相对于 Codis 的不同，它是去中心化的，如图所示，该集群有三个 Redis 节点组成，每个节点负责整个集群的一部分数据，每个节点负责的数据多少可能不一样。这三个节点相互连接组成一个对等的集群，它们之间通过一种特殊的二进制协议相互交互集群信
* Redis Cluster 将所有数据划分为 16384 的 slots，它比 Codis 的 1024 个槽划分的更为精细，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中，它不像 Codis，它不需要另外的分布式存储来存储节点槽位信息
* Cluster 默认会对 key 值使用 crc32 算法进行 hash 得到一个整数值，然后用这个整数值对 16384 进行取模来得到具体槽位
* Redis Cluster 提供了工具 redis-trib 可以让运维人员手动调整槽位的分配情况，
* Redis 迁移的单位是槽，Redis 一个槽一个槽进行迁移，当一个槽正在迁移时，这个槽就处于中间过渡状态。
* 从源节点获取内容 => 存到目标节点 => 从源节点删除内容
* Redis Cluster 可以为每个主节点设置若干个从节点，单主节点故障时，集群会自动将其中某个从节点提升为主节点
* Redis Cluster 提供了一种选项cluster-node-timeout，表示当某个节点持续 timeout 的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换 (数据的重新复制)。
* 因为 Redis Cluster 是去中心化的，一个节点认为某个节点失联了并不代表所有的节点都认为它失联了。所以集群还得经过一次协商的过程，只有当大多数节点都认定了某个节点失联了，集群才认为该节点需要进行主从切换来容错。
  Redis 集群节点采用 Gossip 协议来广播自己的状态以及自己对整个集群认知的改变。比如一个节点发现某个节点失联了 (PFail)，
  它会将这条信息向整个集群广播，其它节点也就可以收到这点失联信息。如果一个节点收到了某个节点失联的数量 (PFail Count) 
  已经达到了集群的大多数，就可以标记该节点为确定下线状态 (Fail)，然后向整个集群广播，强迫其它节点也接收该节点已经下线的事实，并立即对该失联节点进行主从切换
* 客户端保存了槽位和节点的映射关系表，它需要即时得到更新，才可以正常地将某条指令发到正确的节点中。

* 集群的分布式锁问题
    - Redlock 算法
    - 如果你很在乎高可用性，希望挂了一台 redis 完全不受影响，那就应该考虑 redlock。不过代价也是有的，需要更多的 redis 实例，
      性能也下降了，代码上还需要引入额外的 library，运维上也需要特殊对待，这些都是需要考虑的成本，使用前请再三斟酌

### 过期策略
* 定期删除
* 懒惰删除

redis 会将每个设置了过期时间的 key 放入到一个独立的字典中，以后会定时遍历这个字典来删除到期的 key。除了定时遍历之外，
它还会使用惰性策略来删除过期的 key，所谓惰性策略就是在客户端访问这个 key 的时候，redis 对 key 的过期时间进行检查，
如果过期了就立即删除。定时删除是集中处理，惰性删除是零散处理

在一些活动系统中，因为活动是一期一会，下一期活动举办时，前面几期的很多数据都可以丢弃了，所以需要给相关的活动数据设置一个
过期时间，以减少不必要的 Redis 内存占用。如果不加注意，你可能会将过期时间设置为活动结束时间再增加一个常量的冗余时间，
如果参与活动的人数太多，就会导致大量的 key 同时过期。

从库不会进行过期扫描，从库对过期的处理是被动的。主库在 key 到期时，会在 AOF 文件里增加一条 del 指令，同步到所有的从库，从库通过执行这条 del 指令来删除过期的 key。

### 内存淘汰
当 Redis 内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)。交换会让 Redis 的性能急剧下降，对于访问量比较频繁的 Redis 来说，这样龟速的存取效率基本上等于不可用。
用户自己决定该如何腾出新的空间以继续提供读写服务。
 noeviction 不会继续服务写请求 (DEL 请求可以继续服务)，读请求可以继续进行。这样可以保证不会丢失数据，但是会让线上的业务不能持续进行。这是默认的淘汰策略。
 volatile-lru 尝试淘汰设置了过期时间的 key，最少使用的 key 优先被淘汰。没有设置过期时间的 key 不会被淘汰，这样可以保证需要持久化的数据不会突然丢失。
 volatile-ttl 跟上面一样，除了淘汰的策略不是 LRU，而是 key 的剩余寿命 ttl 的值，ttl 越小越优先被淘汰。
 volatile-random 跟上面一样，不过淘汰的 key 是过期 key 集合中随机的 key。
 allkeys-lru 区别于 volatile-lru，这个策略要淘汰的 key 对象是全体的 key 集合，而不只是过期的 key 集合。这意味着没有设置过期时间的 key 也会被淘汰。
 allkeys-random 跟上面一样，不过淘汰的策略是随机的 key。
 volatile-xxx 策略只会针对带过期时间的 key 进行淘汰，allkeys-xxx 策略会对所有的 key 进行淘汰。如果你只是拿 Redis 做缓存，
那应该使用 allkeys-xxx，客户端写缓存时不必携带过期时间。如果你还想同时使用 Redis 的持久化功能，那就使用 volatile-xxx 策略，
这样可以保留没有设置过期时间的 key，它们是永久的 key 不会被 LRU 算法淘汰。






## 高可用
持久化：持久化是最简单的高可用方法，有时甚至不被归为高可用的手段，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。

复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份以及对于读操作的负载均衡和简单的故障恢复。缺陷是故障恢复无法自动化、写操作无法负载均衡、存储能力受到单机的限制。

哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷是写操作无法负载均衡、存储能力受到单机的限制。

集群：通过集群，Redis解决了写操作无法负载均衡以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。

* 持久化
    - RDB 当前数据保存到硬盘，快照持久化
        - 手动触发 save + bgsave
        - 自动触发 在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。
        - 优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。
        - 缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF
        持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。
   
    - AOF 将每次执行的写命令保存到硬盘.实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，
      不过RDB持久化仍然有其用武之地
        - Append Only File
        - AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大

* 复制
* 哨兵
* 集群

#### Redis是单线程的，但Redis为什么这么快？
    1、完全基于内存，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于HashMap，HashMap的优势就是查找和操作的时间复杂度都是O(1)；
    2、数据结构简单，对数据操作也简单，Redis中的数据结构是专门进行设计的；
    3、采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；
    4、使用多路I/O复用模型，非阻塞IO；这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程
    5、使用底层模型不同，它们之间底层实现方式以及与客户端之间通信的应用协议不一样，Redis直接自己构建了VM 机制 ，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；

多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，
当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。


redis的io模型主要是基于epoll实现的，不过它也提供了 select和kqueue的实现，默认采用epoll。
那么epoll到底是个什么东西呢？ 其实只是众多i/o多路复用技术当中的一种而已，但是相比其他io多路复用技术(select, poll等等)，epoll有诸多优点：
　　1. epoll 没有最大并发连接的限制，上限是最大可以打开文件的数目，这个数字一般远大于 2048, 一般来说这个数目和系统内存关系很大  ，具体数目可以 cat /proc/sys/fs/file-max 察看。
　　2. 效率提升， Epoll 最大的优点就在于它只管你“活跃”的连接 ，而跟连接总数无关，因此在实际的网络环境中， Epoll 的效率就会远远高于 select 和 poll 。
　　3. 内存拷贝， Epoll 在这点上使用了“共享内存 ”，这个内存拷贝也省略了。

epoll与select/poll的区别
     select，poll，epoll都是IO多路复用的机制。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个描述符就绪，能够通知程序进行相应的操作。
     select的本质是采用32个整数的32位，即32*32= 1024来标识，fd值为1-1024。当fd的值超过1024限制时，就必须修改FD_SETSIZE的大小。这个时候就可以标识32*max值范围的fd。
     poll与select不同，通过一个pollfd数组向内核传递需要关注的事件，故没有描述符个数的限制，pollfd中的events字段和revents分别用于标示关注的事件和发生的事件，故pollfd数组只需要被初始化一次。
     epoll还是poll的一种优化，返回后不需要对所有的fd进行遍历，在内核中维持了fd的列表。select和poll是将这个内核列表维持在用户态，然后传递到内核中。与poll/select不同，epoll不再是一个单独的系统调用，而是由epoll_create/epoll_ctl/epoll_wait三个系统调用组成，后面将会看到这样做的好处。epoll在2.6以后的内核才支持。
————————————————
原文链接：https://blog.csdn.net/wxy941011/article/details/80274233


* 单进程单线程好处
    - 代码更清晰，处理逻辑更简单
    - 不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗
    - 不存在多进程或者多线程导致的切换而消耗CPU
* 单进程单线程弊端
    - 无法发挥多核CPU性能，不过可以通过在单机开多个Redis实例来完善；
    
    
    
### Redis 内存不足怎样处理
* 集群扩展
    - codis
    - cluster
* 注意设置超时时间


### ZSet
* ZADD key score1 member1 [score2 member2]
* https://www.runoob.com/redis/redis-sorted-sets.html









### 相关面试题
* Redis 单key值过大有什么问题？ 优化方式是什么
    - 由于redis是单线程运行的，如果一次操作的value很大会对整个redis的响应时间造成负面影响
    - 解决方案
        - 单个的数据拆分： 可以尝试将对象分拆成几个key-value， 使用multiGet获取值，这样分拆的意义在于分拆单次操作的压力，
           将操作压力平摊到多个redis实例中，降低对单个redis的IO影响；
        - 集合的数据，提前 hash 拆分


* 单机限流
    -  Java单机限流可以使用AtomicInteger，RateLimiter或Semaphore来实现

* 分布式限流
    - Redis 4.0 提供了一个限流 Redis 模块，它叫 redis-cell。该模块也使用了漏斗算法，并提供了原子的限流指令
    - redis + lua 脚本，自己写，主要应用 guava 的 RateLimiter 的思想

* 设计延时队列
    - PriorityQueue 定时线程轮询
    - Zset 定时线程轮询

* Redis设计延迟队列：
    - Redis的有序集合天然支持这种场景，
    - $redis -> zAdd('notify_msg_queue', '1553053550', '1553053550-1234567891-0');//值：当前时间戳-订单号-通知次数
    - $redis -> zRangeByScore('notify_msg_queue', 0, '1553053550');//排序因子用时间戳，这样能去除之前到现在的所有数据
    - $redis -> zRem('notify_msg_queue', '1553053550-1234567891-0')；//指定删除对应的值
    - 设计原理：队列名字为：notify_msg_queue，因子为当前时间戳，值为【当前时间戳-订单号-通知次数】，获取的时候
    - 如果通过zRangeByScore拿到对应的值能后处理值，根据 “-”符号分割值，如果时间戳 <= ，能后根据订单好通知业务方
    - 的通知接口，如果通知成功则zRem删除对应值从消息队列中移除，如果通知是吧删除原来的值，重新赋新值入消息队列：历史时间戳+4分钟（若都是败就依次增加：4m,10m,10m,1h,2h,6h,15h，知道15h后）
